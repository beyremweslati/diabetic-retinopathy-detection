# DÃ©tection de RÃ©tinopathie DiabÃ©tique avec Apache Spark

Projet de machine learning utilisant **Apache Spark MLlib** pour dÃ©tecter la rÃ©tinopathie diabÃ©tique Ã  partir d'images de rÃ©tine, dÃ©ployÃ© avec Docker et servi via une API Flask.

## Description

Ce projet implÃ©mente un systÃ¨me complet de dÃ©tection de rÃ©tinopathie diabÃ©tique utilisant l'apprentissage automatique distribuÃ© :

- **Apache Spark MLlib** pour l'entraÃ®nement distribuÃ© de modÃ¨les (RÃ©gression Logistique, Random Forest, SVM)
- **API REST Flask** pour servir les prÃ©dictions
- **Extraction de caractÃ©ristiques** Ã  partir d'images de rÃ©tine (statistiques RGB, HSV, dÃ©tection de contours, moments de Hu)
- **Docker Compose** pour un dÃ©ploiement et une orchestration faciles
- **Interface web** pour la comparaison de modÃ¨les et les prÃ©dictions

Le systÃ¨me entraÃ®ne des modÃ¨les de classification binaire pour dÃ©tecter la prÃ©sence de rÃ©tinopathie diabÃ©tique Ã  partir de caractÃ©ristiques d'images de rÃ©tine prÃ©traitÃ©es.

## ğŸ“Š Dataset

**Source :** Dataset de DÃ©tection de RÃ©tinopathie DiabÃ©tique (https://www.kaggle.com/datasets/sovitrath/diabetic-retinopathy-224x224-2019-data)

**Total d'images :** 3662 images de rÃ©tine en couleur  
**Classes :** 5 niveaux de sÃ©vÃ©ritÃ©

- No DR (Sain) : 1805 images
- Mild (LÃ©ger) : 370 images
- Moderate (ModÃ©rÃ©) : 999 images
- Severe (SÃ©vÃ¨re) : 193 images
- Proliferative DR (ProlifÃ©ratif) : 295 images

**Classification binaire :** Les images sont Ã©tiquetÃ©es comme saines (0) ou prÃ©sentant une rÃ©tinopathie diabÃ©tique (1-4).

**CaractÃ©ristiques :** 42 caractÃ©ristiques extraites par image incluant :

- Statistiques de couleur RGB et HSV
- CaractÃ©ristiques d'histogramme
- DÃ©tection de contours (Canny)
- Moments de Hu
- MÃ©triques de contraste et de luminositÃ©

## DÃ©marrage

### 1. Cloner le projet

```bash
git clone https://github.com/beyremweslati/diabetic-retinopathy-detection.git
```

### 2. Construire les Images Docker

```bash
docker compose build
```

Cela construira toutes les images nÃ©cessaires :

- Cluster Spark (master + 2 workers)
- Environnement Jupyter Notebook
- Serveur API Flask
- Serveur web frontend

### 3. DÃ©marrer Tous les Services

```bash
docker compose up -d
```

## EntraÃ®nement des ModÃ¨les

### Option 1 : Utiliser les Notebooks Jupyter

1. AccÃ©der Ã  Jupyter sur **http://localhost:8888**
2. Naviguer vers `notebooks/`
3. ExÃ©cuter les notebooks dans l'ordre :
   - `data_preparation.ipynb` - Extrait les caractÃ©ristiques des images
   - `train_spark_models.ipynb` - EntraÃ®ne les modÃ¨les Spark MLlib
   - `train_sklearn_models.ipynb` - EntraÃ®ne les modÃ¨les scikit-learn (optionnel, pour comparaison)

## ğŸŒ Points d'AccÃ¨s

| Service             | URL                   | Description                        |
| ------------------- | --------------------- | ---------------------------------- |
| **Frontend**        | http://localhost:3000 | Interface web pour les prÃ©dictions |
| **API Flask**       | http://localhost:5000 | Endpoints de l'API REST            |
| **Jupyter**         | http://localhost:8888 | Environnement de notebooks         |
| **Spark Master UI** | http://localhost:8080 | Monitoring du cluster Spark        |
| **Spark Worker 1**  | http://localhost:8081 | Statut du worker                   |
| **Spark Worker 2**  | http://localhost:8082 | Statut du worker                   |

Trois modÃ¨les de machine learning sont entraÃ®nÃ©s avec **Apache Spark MLlib** :

| ModÃ¨le                    | Description                   |
| ------------------------- | ----------------------------- |
| **RÃ©gression Logistique** | Classification linÃ©aire       |
| **Random Forest**         | Apprentissage par ensemble    |
| **SVM LinÃ©aire**          | Machine Ã  vecteurs de support |

Tous les modÃ¨les utilisent :

- **StandardScaler** pour la normalisation des caractÃ©ristiques
- **Validation croisÃ©e** pour l'ajustement des hyperparamÃ¨tres
- **Classification binaire** (sain vs. rÃ©tinopathie diabÃ©tique)

## ğŸ“Š Endpoints de l'API

### Endpoints Principaux

```bash
GET  /models              # Lister les modÃ¨les disponibles
POST /predict-image       # PrÃ©dire Ã  partir d'une image uploadÃ©e
GET  /results             # Obtenir les rÃ©sultats d'entraÃ®nement
```

## ğŸ“ Structure du Projet

```
retinopathie/
â”œâ”€â”€ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ Dockerfile.spark            # Image du cluster Spark
â”œâ”€â”€ Dockerfile.jupyter          # Environnement Jupyter
â”œâ”€â”€ Dockerfile.flask            # Image de l'API Flask
â”œâ”€â”€ Dockerfile.frontend         # Image du frontend web
â”‚
â”œâ”€â”€ dataset2/                   # RÃ©pertoire du dataset
â”‚   â”œâ”€â”€ train.csv               # Labels des images
â”‚   â”œâ”€â”€ colored_images/         # Images de rÃ©tine (5 classes)
â”‚   â””â”€â”€ processed/              # CaractÃ©ristiques traitÃ©es (train/val/test)
â”‚
â”œâ”€â”€ notebooks/                  # Notebooks Jupyter
â”‚   â”œâ”€â”€ data_preparation.ipynb
â”‚   â”œâ”€â”€ train_spark_models.ipynb
â”‚   â””â”€â”€ train_sklearn_models.ipynb
â”‚
â”œâ”€â”€ models/                     # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ spark_logistic_regression/
â”‚   â”œâ”€â”€ spark_random_forest/
â”‚   â”œâ”€â”€ spark_svm/
â”‚   â””â”€â”€ spark_results.csv
â”‚
â”œâ”€â”€ api/                        # API Flask
â”‚   â””â”€â”€ app.py
â”‚
â””â”€â”€ frontend/                   # Interface web
    â”œâ”€â”€ index.html
    â”œâ”€â”€ styles.css
    â””â”€â”€ script.js
```

## ğŸ› ï¸ Stack Technologique

- **Apache Spark 3.5.0** - Calcul distribuÃ©
- **PySpark MLlib** - Algorithmes de machine learning
- **Flask** - Framework d'API REST
- **Docker & Docker Compose** - Conteneurisation
- **Jupyter Notebook** - DÃ©veloppement interactif
- **OpenCV & scikit-image** - Traitement d'images
- **NumPy & Pandas** - Manipulation de donnÃ©es
