services:
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./dataset2:/home/data
      - ./notebooks:/home/notebooks
      - ./models:/home/models
      - ./scripts:/home/scripts
    networks:
      - spark-network
    command: >
      bash -c "
        /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      "

  spark-worker-1:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./dataset2:/home/data
      - ./notebooks:/home/notebooks
      - ./models:/home/models
    networks:
      - spark-network
    command: >
      bash -c "
        /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "

  spark-worker-2:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./dataset2:/home/data
      - ./notebooks:/home/notebooks
      - ./models:/home/models
    networks:
      - spark-network
    command: >
      bash -c "
        /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "

  jupyter:
    build:
      context: .
      dockerfile: Dockerfile.jupyter
    container_name: jupyter-notebook
    hostname: jupyter
    depends_on:
      - spark-master
    ports:
      - "8888:8888"
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - JUPYTER_ENABLE_LAB=yes
    volumes:
      - ./dataset2:/home/data
      - ./notebooks:/home/notebooks
      - ./models:/home/models
      - ./scripts:/home/scripts
    networks:
      - spark-network
    command: >
      bash -c "
        jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --notebook-dir=/home/ --NotebookApp.token='' --NotebookApp.password=''
      "

  flask-api:
    build:
      context: .
      dockerfile: Dockerfile.flask
    container_name: flask-api
    hostname: flask-api
    depends_on:
      - spark-master
    ports:
      - "5000:5000"
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - FLASK_ENV=development
    volumes:
      - ./dataset2:/home/data
      - ./models:/home/models
      - ./api:/home/api
    networks:
      - spark-network
    command: >
      bash -c "
        cd /home/api && python app.py
      "

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: frontend
    ports:
      - "3000:80"
    depends_on:
      - flask-api
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge
